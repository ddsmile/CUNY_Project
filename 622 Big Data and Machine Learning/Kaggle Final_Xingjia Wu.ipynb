{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle competition -- Xingjia Wu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "# import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import misc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.stats import itemfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)  # for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in training dataset from 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_loc = r'/root/sharedfolder/images'\n",
    "file_name = r'/root/sharedfolder/new_legend.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = pd.read_csv(file_name)\n",
    "edata = e[['image', 'emotion', 'new_emotion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral      5991\n",
       "happiness    5041\n",
       "angry         418\n",
       "fear          343\n",
       "sadness       256\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edata['new_emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "pixel = 32 # image resize to 32X32\n",
    "imageResize = (pixel, pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(edata)-925 # exclude images with emotion but no pictures and the first four colorful one\n",
    "X = np.empty(shape = [n-4, pixel, pixel]) # exclude first four\n",
    "Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = 0\n",
    "for i in range(4,n):\n",
    "#     try:\n",
    "        f = os.path.join(file_loc,edata['image'][i])\n",
    "        frame = misc.imread(f)\n",
    "        frameResize = misc.imresize(frame, imageResize) # Resize into 96\n",
    "        X[m] = frameResize\n",
    "        Y.append(edata['new_emotion'][i])\n",
    "        m += 1\n",
    "#     except:\n",
    "#         m += 1\n",
    "#         print(edata['image'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Split dataset into train (75%) and test (25%) sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_train)\n",
    "encoded = encoder.transform(Y_train)\n",
    "Y_train = np_utils.to_categorical(encoded)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y_test)\n",
    "encoded = encoder.transform(Y_test)\n",
    "Y_test = np_utils.to_categorical(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'fear', 'happiness', 'neutral', 'sadness'], \n",
       "      dtype='|S9')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform([0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = pixel, pixel\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape:', (8340, 1, 32, 32))\n",
      "(8340, 'train samples')\n",
      "(2780, 'test samples')\n",
      "*********************************\n",
      "('Y_train shape:', (8340, 5))\n",
      "(8340, 'train samples')\n",
      "(2780, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "print \"*********************************\"\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print(Y_train.shape[0], 'train samples')\n",
    "print(Y_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (1, img_rows, img_cols)\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "batch_size = 128\n",
    "nb_classes = 5 # was 6 for first 2000 images\n",
    "nb_epoch = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1],\n",
    "                        border_mode='valid',\n",
    "                        input_shape=input_shape))\n",
    "\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(nb_filters, kernel_size[0], kernel_size[1], border_mode = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model with inline augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "166800/166800 [==============================] - 1203s - loss: 0.8094 - acc: 0.6570 - val_loss: 0.5404 - val_acc: 0.8144\n",
      "Epoch 2/12\n",
      "166800/166800 [==============================] - 1211s - loss: 0.6234 - acc: 0.7740 - val_loss: 0.4603 - val_acc: 0.8385\n",
      "Epoch 3/12\n",
      "166800/166800 [==============================] - 1213s - loss: 0.5572 - acc: 0.8033 - val_loss: 0.4243 - val_acc: 0.8583\n",
      "Epoch 4/12\n",
      "166800/166800 [==============================] - 1215s - loss: 0.5202 - acc: 0.8175 - val_loss: 0.4042 - val_acc: 0.8676\n",
      "Epoch 5/12\n",
      "166800/166800 [==============================] - 1246s - loss: 0.4957 - acc: 0.8277 - val_loss: 0.3911 - val_acc: 0.8691\n",
      "Epoch 6/12\n",
      "166800/166800 [==============================] - 1271s - loss: 0.4792 - acc: 0.8334 - val_loss: 0.3765 - val_acc: 0.8773\n",
      "Epoch 7/12\n",
      "166800/166800 [==============================] - 1273s - loss: 0.4588 - acc: 0.8404 - val_loss: 0.3803 - val_acc: 0.8788\n",
      "Epoch 8/12\n",
      "166800/166800 [==============================] - 1322s - loss: 0.4480 - acc: 0.8444 - val_loss: 0.3638 - val_acc: 0.8856\n",
      "Epoch 9/12\n",
      "166800/166800 [==============================] - 1298s - loss: 0.4360 - acc: 0.8482 - val_loss: 0.3795 - val_acc: 0.8755\n",
      "Epoch 10/12\n",
      "166800/166800 [==============================] - 1248s - loss: 0.4271 - acc: 0.8515 - val_loss: 0.3652 - val_acc: 0.8831\n",
      "Epoch 11/12\n",
      "166800/166800 [==============================] - 1225s - loss: 0.4175 - acc: 0.8555 - val_loss: 0.3521 - val_acc: 0.8863\n",
      "Epoch 12/12\n",
      "166800/166800 [==============================] - 1219s - loss: 0.4097 - acc: 0.8579 - val_loss: 0.3462 - val_acc: 0.8885\n",
      "Training duration : 14953.2123029\n",
      "2780/2780 [==============================] - 7s     \n",
      "Network's test score [loss, accuracy]: [0.34624413363367534, 0.88848920863309355]\n",
      "Network's time 249.340742401 minutes\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "train_datagen = ImageDataGenerator(\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.05,\n",
    "    height_shift_range = 0.05,\n",
    "    shear_range = 0.1,\n",
    "    zoom_range = 0.1,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train, Y_train, batch_size = 256)\n",
    "\n",
    "# model.reset_states()\n",
    "start_time = time.time()\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=len(X_train)*20,\n",
    "    nb_epoch=12,\n",
    "    validation_data=(X_test, Y_test))\n",
    "\n",
    "print \"Training duration : {0}\".format(time.time() - start_time)\n",
    "score = model.evaluate(X_test, Y_test, batch_size = batch_size)\n",
    "\n",
    "print \"Network's test score [loss, accuracy]: {0}\".format(score)\n",
    "print \"Network's time {0} minutes\".format((time.time() - start_time)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model_unbalanced_aug.json\", \"w\") as json_file:\n",
    "\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "\n",
    "model.save_weights(\"model_unbalanced_aug.h5\")\n",
    "\n",
    "print(\"Saved model to disk\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Read in test image preprocessed by OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modified data\n",
    "indir = r'/root/sharedfolder/testFace'\n",
    "piclist = os.listdir(indir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel = 32\n",
    "n = len(piclist)\n",
    "X = np.empty(shape = [n, pixel, pixel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "        f = os.path.join(indir, piclist[i])\n",
    "        frame = misc.imread(f,  flatten=True)\n",
    "        frame = misc.imresize(frame,(pixel, pixel) )\n",
    "        X[i]= frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 'test samples')\n"
     ]
    }
   ],
   "source": [
    "X_test = X.reshape(X.shape[0], 1, pixel, pixel)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_file = open('model_unbalanced_aug.json', 'r')\n",
    "\n",
    "loaded_model_json = json_file.read()\n",
    "\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "\n",
    "loaded_model.load_weights(\"model_unbalanced_aug.h5\")\n",
    "\n",
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = loaded_model.predict(X_test, verbose = 0)\n",
    "predEmotion = np.argmax(predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = pd.concat([pd.Series(piclist), pd.Series(predEmotion)], axis=1)\n",
    "label.columns = ['Image', 'code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ecode = {0:'anger', 1:'fear', 2:'happiness', 3:'neutral', 4:'sadness'}\n",
    "edf = pd.DataFrame.from_dict(ecode, orient='index').reset_index()\n",
    "edf = edf.rename(columns={'index': 'code', 0: 'Emotion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resultTable = pd.merge(label, edf, on = ['code'], how='inner')\n",
    "result = resultTable.drop(['code'], 1)\n",
    "\n",
    "# Write out the csv\n",
    "result.to_csv('evaluation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
